<!DOCTYPE html>
<html lang="en-US">
  <head>
    <title>Hantao Yao | University of Science and Technology of China</title>

    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="The Minimal Light is a simple and elegant jekyll theme for academic personal homepage.">
    
    <meta name="keywords" content="minimal light">
    
    
    <link rel="canonical" href="https://minimal-light-theme.yliu.me/"/>
    

    <link rel="icon" media="(prefers-color-scheme:dark)" href="./assets/img/favicon-dark.png" type="image/png" />
    <link rel="icon" media="(prefers-color-scheme:light)" href="./assets/img/favicon.png" type="image/png" />
    <script src="./assets/js/favicon-switcher.js" type="application/javascript"></script>

    <link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin=anonymous>
    <link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin=anonymous>

    
    <link rel="stylesheet" href="./assets/css/style.css">
    <link rel="stylesheet" href="./assets/css/publications.css">
    

  </head>
  <body>
    <div class="wrapper">
      <aside class="sidebar" style="overflow:auto;"></aside>
      <header>
        
        <a class="image avatar"><img src="img/htyao24.jpg" alt="Hantao Yao"></a>
        

        <h1>Hantao Yao</h1>

        <h1>姚涵涛</h1>

        
        <position style="font-size:1.10rem;">Professor</position>
        <br>
        
        <a href="" rel="noopener"><autocolor>University of Science and Technology of China(中国科学技术大学)</autocolor></a>


        <br>
        
        
        <email>yaohantao (at) ustc.edu.cn</email>
        

        <br>
        <br>
        <div class="social-icons">
        
        <a style="margin: 0 5px 0 0" href="https://scholar.google.com/citations?user=-xtf1c0AAAAJ&hl=en">
          <i class="ai ai-google-scholar" style="font-size:1.2rem"></i>
        </a>  
        

        
        <a style="margin: 0 5px 0 0" href="img/hantao_cv.pdf">
          <i class="ai ai-cv" style="font-size:1.3rem;"></i>
        </a>
        

        
        <a style="margin: 0 5px 0 0" href="https://github.com/htyao89/">
          <i class="fab fa-github"></i>
        </a>
        

        
        <a style="margin: 0 5px 0 0" href="https://dblp.uni-trier.de/pid/167/3478.html">DBLP
        </a>
         
        </div>
        <br>

      </header>
      <section>

<h2 id="about-me">About Me</h2>
<p> received a B.E. degree from Xidian University in 2012 and received a Ph.D. degree from the Institute of Computing Technology, University of Chinese Academy of Sciences in 2018. After that,  I worked as an assistant professor at the National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences. Now, I am a professor at the University of Science and Technology of China</p>

<h2 id="research-interests">Research Interests</h2>

<ul>
  <li><strong>Computer Vision:</strong> object recognition, person re-identification, object detection</li>
  <li><strong>Machine Learning:</strong> domain adaptation, incremental learning, prompt tuning</li>
</ul>

<h2 id="educations">Educations and Work</h2>
<ul>
  <li>2008.9-2012.7 Xidian University(西安电子科技大学)，Bachelor degree </li>
  <li>2012.9-2018.7 Institute of Computing Technology of the Chinese Academy of Sciences（中科院计算所)， Ph.D</li>
  <li>2012.9-2025.2 Institute of Automation of the Chinese Academy of Sciences（中科院自动化所), Associate Professor </li>
  <li>2025.2- University of Science and Technology of China, Professor</li>
</ul>

<h2 id="news">News</h2>

<ul>
  <li style="margin: 10px 0px 0px 5px" >2025.3, two papers on Cross-domain Object Detection and Continual learning accepted by <strong>CVPR25</strong>.</li>

  <li style="margin: 10px 0px 0px 5px" >2025.2, one papers on Domain Generalization accepted by <strong>TMM</strong>.</li>

  <li style="margin: 10px 0px 0px 5px" >2024.11, one papers on Cross-domain Object Detection accepted by <strong>NeurIPS24</strong>.</li>
 
  <li style="margin: 10px 0px 0px 5px" >2024.7, one papers on Camera-Incremental Person Re-Identification accepted by <strong>TMM</strong>.</li>
  
  <li style="margin: 10px 0px 0px 5px" >2024.5, one papers on Cross-domain Object Detection accepted by <strong>TIP</strong>.</li>
  
  <li style="margin: 10px 0px 0px 5px" >2024.5, two papers accepted by <strong>ICML24</strong>.</li>
  
  <li style="margin: 10px 0px 0px 5px" >2024.4, one paper on Visual-Audio Class Incremental Learning accepted by <strong>TPAMI</strong>.</li>
  
  <li style="margin: 10px 0px 0px 5px" >2024.3, one paper on Cross-domain Object Detection accepted by <strong>TIP</strong>.</li>
  
  <li style="margin: 10px 0px 0px 5px" >2024.3, one paper on Prompt Tuning accepted by <strong>CVPR24</strong>.</li>

</ul>

<h2 id="publications" style="margin: 2px 0px -15px;">Publications</h2>

<div class="publications">
<ol class="bibliography">

  <li>
    <div class="pub-row">
      <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
        <img src="./img/CIOR.png" class="teaser img-fluid z-depth-1" style="width=100;height=40%" />
                <abbr class="badge">TMM 2024</abbr>
      </div>
      <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
          <div class="title"><a href="https://arxiv.org/pdf/2305.15909">Camera-Incremental Object Re-Identification With Identity Knowledge Evolution</a></div>
          <div class="author"><strong>Hantao Yao</strong>, Jifei Luo, Lu Yu, Changsheng Xu</div>
          <div class="periodical"><em>IEEE Transactions on Multimedia <strong>(TMM)</strong>, 2024.</em>
          </div>
        <div class="links">
           
          <a href="https://arxiv.org/pdf/2305.15909" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
           
        </div>
      </div>
    </div>
    </li>
    <br />
  

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="./img/tcp.png" class="teaser img-fluid z-depth-1" style="width=100;height=40%" />
            <abbr class="badge">CVPR 2024</abbr>
  </div>
  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
      <div class="title"><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Yao_TCPTextual-based_Class-aware_Prompt_tuning_for_Visual-Language_Model_CVPR_2024_paper.pdf">Tcp: Textual-based class-aware prompt tuning for visual-language model</a></div>
      <div class="author">Hantao Yao, Rui Zhang, Changsheng Xu</div>
      <div class="periodical"><em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2024.</em>
      </div>
    <div class="links">
       
      <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Yao_TCPTextual-based_Class-aware_Prompt_tuning_for_Visual-Language_Model_CVPR_2024_paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
       
      <a href="https://github.com/htyao89/Textual-based_Class-aware_prompt_tuning" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
      
    </div>
  </div>
</div>
</li>
<br />


<li>
  <div class="pub-row">
    <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
      <img src="./img/TPAMI24.png" class="teaser img-fluid z-depth-1" style="width=100;height=40%" />
              <abbr class="badge">TPAMI 2024</abbr>
    </div>
    <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
        <div class="title"><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Yao_TCPTextual-based_Class-aware_Prompt_tuning_for_Visual-Language_Model_CVPR_2024_paper.pdf">Hierarchical Augmentation and Distillation for Class Incremental Audio-Visual Video Recognition</a></div>
        <div class="author">Yukun Zuo, Hantao Yao, Liansheng Zhuang, Changsheng Xu</div>
        <div class="periodical"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence <strong>(TAPMI)</strong>, 2024.</em>
        </div>
      <div class="links">
         
        <a href="https://arxiv.org/pdf/2401.06287.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
         
      </div>
    </div>
  </div>
  </li>
  <br />

  <li>
    <div class="pub-row">
      <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
        <img src="./img/NeurIPS24.png" class="teaser img-fluid z-depth-1" style="width=100;height=40%" />
                <abbr class="badge">NeurIPS 2024</abbr>
      </div>
      <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
          <div class="title"><a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/bb71b5567ee985e0a4cee54ade19275c-Paper-Conference.pdf">Da-ada: Learning domain-aware adapter for domain adaptive object detection</a></div>
          <div class="author">Haochen Li, Rui Zhang, Hantao Yao, Xin Zhang, Yifan Hao, Xinkai Song, Xiaqing Li, Yongwei Zhao, Yunji Chen, Ling Li</div>
          <div class="periodical"><em>Advances in Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2024.</em>
          </div>
        <div class="links">
           
          <a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/bb71b5567ee985e0a4cee54ade19275c-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
           
        </div>
      </div>
    </div>
    </li>
    <br />

    <li>
      <div class="pub-row">
        <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
          <img src="./img/ICML24.png" class="teaser img-fluid z-depth-1" style="width=100;height=40%" />
                  <abbr class="badge">ICML 2024</abbr>
        </div>
        <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
            <div class="title"><a href="https://arxiv.org/pdf/2406.02343">Cluster-aware similarity diffusion for instance retrieval</a></div>
            <div class="author">Jifei Luo, Hantao Yao, Changsheng Xu</div>
            <div class="periodical"><em>International Conference on Machine Learning <strong>(ICML)</strong>, 2024.</em>
            </div>
          <div class="links">
             
            <a href="https://arxiv.org/pdf/2406.02343.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
             
          </div>
        </div>
      </div>
      </li>
      <br />
    </ol>
  </div>

   
    <ul>
    <li>Haihan Gao, Rui Zhang, Qi Yi, <strong>Hantao Yao</strong>, etal: Prompt-based Visual Alignment for Zero-shot Policy Transfer, accepted by ICML24 [<a href="https://arxiv.org/pdf/2406.03250">Paper</a>]</li>
    <li>Jifei Luo, <strong>Hantao Yao</strong>, Changsheng Xu: Cluster-Aware Similarity Diffusion for Instance Retrieval, accepted by ICML24 [<a href="https://arxiv.org/abs/2406.02343">Paper</a>][<a href="https://github.com/jifeiluo/reranking">Code</a>] </li>
    <li>Yukun Zuo, <strong>Hantao Yao</strong>, Liansheng Zhuang, Changsheng Xu: Hierarchical Augmentation and Distillation for Class Incremental Audio-Visual Video Recognition, accepted by TPAMI. [<a href="https://arxiv.org/pdf/2401.06287">Paper</a>][<a href="https://github.com/Play-in-bush/HAD">Code</a>] </li> 
    <li><strong>Hantao Yao</strong>, Rui Zhang, Changsheng Xu: TCP:Textual-based Class-aware Prompt tuning for Visual-Language Model, CVPR 24. [<a href="https://arxiv.org/abs/2311.18231">Paper</a>] [<a href="https://github.com/htyao89/Textual-based_Class-aware_prompt_tuning">Code</a>] </li> 
    <li><strong>姚涵涛</strong> , 余璐, 徐常胜: 视觉语言模型引导的文本知识嵌入的小样本增量学习, 软件学报 23. [<a href="https://www.jos.org.cn/jos/article/pdf/7022">Paper</a>] </li> 
    <li><strong>Hantao Yao</strong>, Rui Zhang, Changsheng Xu: Visual-Language Prompt Tuning With Knowledge-Guided Context Optimization, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023, pp. 6757-6767.  [<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Yao_Visual-Language_Prompt_Tuning_With_Knowledge-Guided_Context_Optimization_CVPR_2023_paper.html">Paper</a>][<a href="https://github.com/htyao89/KgCoO">Code</a>] </li>  
        <li style="margin: 10px 0px 0px 5px" >Sisi You, Yukun Zuo, <strong>Hantao Yao</strong>, Changsheng Xu:Incremental Audio-Visual Fusion for Person Recognition in Earthquake Scene. ACM Trans. Multim. Comput. Commun. Appl. 20(2): 53:1-53:19 (2024)</li>
        <li style="margin: 10px 0px 0px 5px" >Sisi You, <strong>Hantao Yao</strong>, Bing-Kun Bao, Changsheng Xu:Multi-object Tracking with Spatial-Temporal Tracklet Association. ACM Trans. Multim. Comput. Commun. Appl. 20(5): 129:1-129:21 (2024)</li>
        <li style="margin: 10px 0px 0px 5px" >Yifan Jiao, <strong>Hantao Yao</strong>, Changsheng Xu:Dual Instance-Consistent Network for Cross-Domain Object Detection. IEEE Trans. Pattern Anal. Mach. Intell. 45(6): 7338-7352 (2023)</li>
        <li style="margin: 10px 0px 0px 5px" >Yukun Zuo, <strong>Hantao Yao</strong>, Liansheng Zhuang, Changsheng Xu:Dual Structural Knowledge Interaction for Domain Adaptation. IEEE Trans. Multim. 25: 9057-9070 (2023)</li>
        <li style="margin: 10px 0px 0px 5px" >Sisi You, <strong>Hantao Yao</strong> Bing-Kun Bao, Changsheng Xu:UTM: A Unified Multiple Object Tracking Model with Identity-Aware Feature Enhancement. CVPR 2023: 21876-21886</li>
        <li style="margin: 10px 0px 0px 5px" >Haochen Li, Rui Zhang, <strong>Hantao Yao</strong>, Xinkai Song, Yifan Hao, Yongwei Zhao, Ling Li, Yunji Chen:Learning Domain-Aware Detection Head with Prompt Tuning. NeurIPS 2023</li>
        <li style="margin: 10px 0px 0px 5px" >Yukun Zuo, <strong>Hantao Yao</strong>, Liansheng Zhuang, Changsheng Xu:Margin-Based Adversarial Joint Alignment Domain Adaptation. IEEE Trans. Circuits Syst. Video Technol. 32(4): 2057-2067 (2022)</li>
        <li style="margin: 10px 0px 0px 5px" >Sisi You, <strong>Hantao Yao</strong>, Changsheng Xu:Multi-Object Tracking With Spatial-Temporal Topology-Based Detector. IEEE Trans. Circuits Syst. Video Technol. 32(5): 3023-3035 (2022)</li>
        <li style="margin: 10px 0px 0px 5px" >Yaoyu Li, <strong>Hantao Yao</strong>, Changsheng Xu:Intra-Domain Consistency Enhancement for Unsupervised Person Re-Identification. IEEE Trans. Multim. 24: 415-425 (2022)</li>
        <li style="margin: 10px 0px 0px 5px" >Yukun Zuo, <strong>Hantao Yao</strong>, Liansheng Zhuang, Changsheng Xu:Seek Common Ground While Reserving Differences: A Model-Agnostic Module for Noisy Domain Adaptation. IEEE Trans. Multim. 24: 1020-1030 (2022)</li>
        <li style="margin: 10px 0px 0px 5px" ><strong>Hantao Yao</strong>, Shaobo Min, Yongdong Zhang, Changsheng Xu:Attribute-Induced Bias Eliminating for Transductive Zero-Shot Learning. IEEE Trans. Multim. 24: 1933-1942 (2022)</li>    
        <li style="margin: 10px 0px 0px 5px" ><strong>Hantao Yao</strong>, Changsheng Xu: Joint Person Objectness and Repulsion for Person Search. IEEE Trans. Image Process. 30: 685-696 (2021)</li>
        <li style="margin: 10px 0px 0px 5px" >Shaobo Min, Hongtao Xie, <strong>Hantao Yao*</strong>, Xuran Deng, Zheng-Jun Zha, Yongdong Zhang: Hierarchical Granularity Transfer Learning. NeurIPS 2020</li>
        <li style="margin: 10px 0px 0px 5px" >Yukun Zuo, <strong>Hantao Yao</strong>, Changsheng Xu: Category-Level Adversarial Self-Ensembling for Domain Adaptation. ICME 2020: 1-6 </li>
        <li style="margin: 10px 0px 0px 5px" >Shaobo Min, <strong>Hantao Yao</strong>, Hongtao Xie, Chaoqun Wang, Zheng-Jun Zha, Yongdong Zhang: Domain-Aware Visual Bias Eliminating for Generalized Zero-Shot Learning. CVPR 2020: 12661-12670</li>
        <li style="margin: 10px 0px 0px 5px" >Yaoyu Li, <strong>Hantao Yao</strong>, Tianzhu Zhang, and Changsheng Xu. 2020. Part-based Structured Representation Learning for Person Re-identification. ACM Trans. Multimedia Comput. Commun. Appl. 16, 4, Article 134</li>
        <li style="margin: 10px 0px 0px 5px" >Sisi You, <strong>Hantao Yao</strong>, Changsheng Xu, "Multi-Target Multi-Camera Tracking with Optical-based Pose Association," in IEEE Transactions on Circuits and Systems for Video Technology, doi: 10.1109/TCSVT.2020.3036467.</li>
        <li style="margin: 10px 0px 0px 5px" >S. Min, <strong>Hantao Yao</strong>, H. Xie, Z. -J. Zha and Y. Zhang, "Domain-Oriented Semantic Embedding for Zero-Shot Learning," in IEEE Transactions on Multimedia, doi: 10.1109/TMM.2020.3033124.</li>
        <li style="margin: 10px 0px 0px 5px" >Y. Jiao, <strong>Hantao Yao</strong> and C. Xu, "PEN: Pose-Embedding Network for Pedestrian Detection," in IEEE Transactions on Circuits and Systems for Video Technology, doi: 10.1109/TCSVT.2020.3000223.</li>
        <li style="margin: 10px 0px 0px 5px" >Shaobo Min, <strong>Hantao Yao</strong>, Hongtao Xie, Zheng-Jun Zha, Yongdong Zhang: Multi-Objective Matrix Normalization for Fine-Grained Visual Recognition. IEEE Trans. Image Process. 29: 4996-5009 (2020)</li>
        <li style="margin: 10px 0px 0px 5px" >Shaobo Min, <strong>Hantao Yao</strong>, Hongtao Xie, Chaoqun Wang, Zheng-Jun Zha, Yongdong Zhang: Domain-Aware Visual Bias Eliminating for Generalized Zero-Shot Learning. CVPR 2020: 12661-12670</li>
        <li style="margin: 10px 0px 0px 5px" >Longhui Wei, Shiliang Zhang, <strong>Hantao Yao</strong>, Wen Gao, Qi Tian: GLAD: Global-Local-Alignment Descriptor for Scalable Person Re-Identification. IEEE Trans. Multim. 21(4): 986-999 (2019)</li>
        <li style="margin: 10px 0px 0px 5px" ><strong>Hantao Yao</strong>, Shiliang Zhang, Richang Hong, Yongdong Zhang, Changsheng Xu, Qi Tian: Deep Representation Learning With Part Loss for Person Re-Identification. IEEE Trans. Image Process. 28(6): 2860-2871 (2019) </li>
        <li style="margin: 10px 0px 0px 5px" ><strong>Hantao Yao</strong>, Feng Dai, Shiliang Zhang, Yongdong Zhang, Qi Tian, Changsheng Xu: DR2-Net: Deep Residual Reconstruction Network for image compressive sensing. Neurocomputing 359: 483-493 (2019)</li>
        <li style="margin: 10px 0px 0px 5px" >Shaobo Min, Hongtao Xie, Youliang Tian, <strong>Hantao Yao</strong>, Yongdong Zhang:Adaptive Bilinear Pooling for Fine-grained Representation Learning. MMAsia 2019: 2:1-2:6</li>
        <li style="margin: 10px 0px 0px 5px" ><strong>Hantao Yao</strong>, Shiliang Zhang, Chenggang Yan, Yongdong Zhang, Jintao Li, Qi Tian: AutoBD: Automated Bi-Level Description for Scalable Fine-Grained Visual Categorization. IEEE Trans. Image Process. 27(1): 10-23 (2018) </li>
        <li style="margin: 10px 0px 0px 5px" >Yaoyu Li, <strong>Hantao Yao</strong>, Lingyu Duan, Hanxing Yao, Changsheng Xu: Adaptive Feature Fusion via Graph Neural Network for Person Re-identification. ACM Multimedia 2019: 2115-2123</li>
        <li style="margin: 10px 0px 0px 5px" >Shaobo Min, <strong>Hantao Yao</strong>, Hongtao Xie, Zheng-Jun Zha, Yongdong Zhang: Domain-Specific Embedding Network for Zero-Shot Recognition. ACM Multimedia 2019: 2070-2078</li>
        <li style="margin: 10px 0px 0px 5px" ><strong>Hantao Yao</strong>, Shiliang Zhang, Yongdong Zhang, Jintao Li, Qi Tian: One-Shot Fine-Grained Instance Retrieval. ACM Multimedia 2017: 342-350</li>
        <li style="margin: 10px 0px 0px 5px" >Longhui Wei, Shiliang Zhang, <strong>Hantao Yao</strong>, Wen Gao, Qi Tian: GLAD: Global-Local-Alignment Descriptor for Pedestrian Retrieval. ACM Multimedia 2017: 420-428 </li>
        <li style="margin: 10px 0px 0px 5px" ><strong>Hantao Yao</strong>, Shiliang Zhang, Dongming Zhang, Yongdong Zhang, Jintao Li, Yu Wang, Qi Tian: Large-scale person re-identification as retrieval. ICME 2017: 1440-1445</li>
        <li style="margin: 10px 0px 0px 5px" ><strong>Hantao Yao</strong>, Dongming Zhang, Jintao Li, Jianshe Zhou, Shiliang Zhang, Yongdong Zhang: DSP: Discriminative Spatial Part modeling for Fine-Grained Visual Categorization. Image Vis. Comput. 63: 24-37 (2017)</li>
        <li style="margin: 10px 0px 0px 5px" ><strong>Hantao Yao</strong>, Shiliang Zhang, Yongdong Zhang, Jintao Li, Qi Tian: Coarse-to-Fine Description for Fine-Grained Visual Categorization. IEEE Trans. Image Process. 25(10): 4858-4872 (2016)</li>
        <li style="margin: 10px 0px 0px 5px" ><strong>Hantao Yao</strong>, Shiliang Zhang, Fei Xie, Yongdong Zhang, Dongming Zhang, Yu Su, Qi Tian: Orientational Spatial Part Modeling for Fine-Grained Visual Categorization. IEEE MS 2015: 360-367</li>
    </ul>


<h2 id="awards">Awards</h2>
<ul>
  <li>ACM Multimedia Asia 2019, Best Student Paper Award</li>
  <li>China Multimedia 2023, Best Poster Award</li>
  <li>Postdoctoral Innovative Talent Support Program, 2018</li>
  <li>Chinese Academy of Sciences President's Excellence Award</li>
</ul>

<h2 id="services">Services</h2>

<h4 style="margin:0 10px 0;">Conference Reviewers</h4>

<ul style="margin:0 0 5px;">
  <li><a href="http://cvpr2023.thecvf.com/"><autocolor>ICML/NeurIPS/CVPR/ICCV/MM</autocolor></a></li>
</ul>

<h4 style="margin:0 10px 0;">Journal Reviewers</h4>

<ul style="margin:0 0 20px;">
  <li><a href="https://www.computer.org/csdl/journal/tp"><autocolor>T-PAMI，T-IP，T-MM,</autocolor></a></li>
</ul>


      <br>

      
      <p><small>Powered by Jekyll and <a href="https://github.com/yaoyao-liu/minimal-light" target="_blank" rel="noopener">Minimal Light</a> theme.</small></p>
      

      </section>
      <footer>
        
      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
    
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-111540567-4', 'auto');
      ga('send', 'pageview');
    </script>
    
  </body>
</html>
